import random
import re
import requests
from bs4 import BeautifulSoup
from collections import defaultdict, Counter
import numpy as np
import matplotlib.pyplot as plt

def tokenize(text):
    return re.findall(r'\b\w+\b', text.lower())

def build_trigram_model(text):
    tokens = tokenize(text)
    trigrams = [(tokens[i], tokens[i+1], tokens[i+2]) for i in range(len(tokens) - 2)]
    model = defaultdict(Counter)
    for w1, w2, w3 in trigrams:
        model[(w1, w2)][w3] += 1
    return model

def generate_sentence(model, seed, max_length=50):
    sentence = list(seed)
    for _ in range(max_length - 2):
        context = tuple(sentence[-2:])
        if context in model:
            next_word = random.choices(list(model[context].keys()), 
                                       list(model[context].values()))[0]
        else:
            next_word = random.choice(list(model.keys()))[0]
        sentence.append(next_word)
        if next_word in '.!?':
            break
    return ' '.join(sentence)

def laplace_smoothing(model, vocab_size):
    for context in model:
        total_count = sum(model[context].values())
        for word in model[context]:
            model[context][word] = (model[context][word] + 1) / (total_count + vocab_size)
    return model

def get_text_from_url(url):
    try:
        response = requests.get(url)
        response.raise_for_status() 
        soup = BeautifulSoup(response.content, 'html.parser')
        text = soup.get_text()
        start = text.find("*** START OF THIS PROJECT GUTENBERG EBOOK")
        end = text.find("*** END OF THIS PROJECT GUTENBERG EBOOK")
        if start != -1 and end != -1:
            text = text[start:end]
        return text
    except requests.RequestException as e:
        print(f"Error fetching text: {e}")
        return ""

nietzsche_url = 'https://www.gutenberg.org/cache/epub/67979/pg67979.txt'
russell_url = 'https://www.gutenberg.org/cache/epub/75342/pg75342.txt'

nietzsche_text = get_text_from_url(nietzsche_url)
russell_text = get_text_from_url(russell_url)

nietzsche_tokens = tokenize(nietzsche_text)
russell_tokens = tokenize(russell_text)

nietzsche_train = ' '.join(nietzsche_tokens[:int(len(nietzsche_tokens) * 0.8)])
nietzsche_test = ' '.join(nietzsche_tokens[int(len(nietzsche_tokens) * 0.8):])

russell_train = ' '.join(russell_tokens[:int(len(russell_tokens) * 0.8)])
russell_test = ' '.join(russell_tokens[int(len(russell_tokens) * 0.8):])

nietzsche_model = build_trigram_model(nietzsche_train)
russell_model = build_trigram_model(russell_train)

vocab_size = len(set(tokenize(nietzsche_train + russell_train)))
nietzsche_model = laplace_smoothing(nietzsche_model, vocab_size)
russell_model = laplace_smoothing(russell_model, vocab_size)

seed = ('the', 'a', 'once')
for _ in range(1):
    nietzsche_sentence = generate_sentence(nietzsche_model, seed)
    print("Nietzsche:", nietzsche_sentence)
    seed = tuple(nietzsche_sentence.split()[-3:])
    
    russell_sentence = generate_sentence(russell_model, seed)
    print("Russell:", russell_sentence)
    seed = tuple(russell_sentence.split()[-3:])


# Визуализация

def calculate_log_probability(model, sentence):
    tokens = tokenize(sentence)
    log_prob = 0.0
    for i in range(len(tokens) - 2):
        context = (tokens[i], tokens[i + 1])
        next_word = tokens[i + 2]
        if context in model:
            count_next_word = model[context][next_word]
            total_count = sum(model[context].values())
            prob = (count_next_word + 1) / (total_count + len(model))
            log_prob += np.log(prob)
        else:
            log_prob += np.log(1 / (sum(model[context].values()) + len(model)))
    return log_prob

def split_into_sentences(text):
    return re.split(r'(?<=[.!?]) +', text)

nietzsche_test_sentences = split_into_sentences(nietzsche_test)
russell_test_sentences = split_into_sentences(russell_test)

nietzsche_log_probs_russell = [calculate_log_probability(russell_model, sentence) for sentence in nietzsche_test_sentences]
nietzsche_log_probs_nietzsche = [calculate_log_probability(nietzsche_model, sentence) for sentence in nietzsche_test_sentences]
russell_log_probs_russell = [calculate_log_probability(russell_model, sentence) for sentence in russell_test_sentences]
russell_log_probs_nietzsche = [calculate_log_probability(nietzsche_model, sentence) for sentence in russell_test_sentences]

plt.figure(figsize=(14, 12))

plt.subplot(2, 2, 1)
plt.hist(russell_log_probs_russell, bins=40, color='skyblue', alpha=0.8, edgecolor='black')
plt.title('Russell Test Data - Russell Model')
plt.xlabel('Log Probability')
plt.ylabel('Frequency')
plt.grid(axis='y', alpha=0.75)

plt.subplot(2, 2, 2)
plt.hist(russell_log_probs_nietzsche, bins=40, color='salmon', alpha=0.8, edgecolor='black')
plt.title('Russell Test Data - Nietzsche Model')
plt.xlabel('Log Probability')
plt.ylabel('Frequency')
plt.grid(axis='y', alpha=0.75)

plt.subplot(2, 2, 3)
plt.hist(nietzsche_log_probs_russell, bins=40, color='lightgreen', alpha=0.8, edgecolor='black')
plt.title('Nietzsche Test Data - Russell Model')
plt.xlabel('Log Probability')
plt.ylabel('Frequency')
plt.grid(axis='y', alpha=0.75)

plt.subplot(2, 2, 4)
plt.hist(nietzsche_log_probs_nietzsche, bins=40, color='lightcoral', alpha=0.8, edgecolor='black')
plt.title('Nietzsche Test Data - Nietzsche Model')
plt.xlabel('Log Probability')
plt.ylabel('Frequency')
plt.grid(axis='y', alpha=0.75)

plt.tight_layout()
plt.show()
